{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/toufik/anaconda3/envs/workshop/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from statistics import median, mean\n",
    "from collections import Counter\n",
    "\n",
    "LR = 1e-3\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "goal_steps = 500\n",
    "score_requirement = 50\n",
    "initial_games = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()\n",
    "def some_random_games_first():\n",
    "    # Each of these is its own game.\n",
    "    for episode in range(10):\n",
    "        env.reset()\n",
    "        # this is each frame, up to 200...but we wont make it that far.\n",
    "        for t in range(2000):\n",
    "            # This will display the environment\n",
    "            # Only display if you really want to see it.\n",
    "            # Takes much longer to display it.\n",
    "            env.render()\n",
    "            \n",
    "            # This will just create a sample action in any environment.\n",
    "            # In this environment, the action can be 0 or 1, which is left or right\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "            # this executes the environment with an action, \n",
    "            # and returns the observation of the environment, \n",
    "            # the reward, if the env is over, and other info.\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "        env.close()\n",
    "                \n",
    "some_random_games_first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_population():\n",
    "    # [OBS, MOVES]\n",
    "    training_data = []\n",
    "    # all scores:\n",
    "    scores = []\n",
    "    # just the scores that met our threshold:\n",
    "    accepted_scores = []\n",
    "    # iterate through however many games we want:\n",
    "    for _ in range(initial_games):\n",
    "        score = 0\n",
    "        # moves specifically from this environment:\n",
    "        game_memory = []\n",
    "        # previous observation that we saw\n",
    "        prev_observation = []\n",
    "        # for each frame in 200\n",
    "        for _ in range(goal_steps):\n",
    "            # choose random action (0 or 1)\n",
    "            action = random.randrange(0,2)\n",
    "            # do it!\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # notice that the observation is returned FROM the action\n",
    "            # so we'll store the previous observation here, pairing\n",
    "            # the prev observation to the action we'll take.\n",
    "            if len(prev_observation) > 0 :\n",
    "                game_memory.append([prev_observation, action])\n",
    "            prev_observation = observation\n",
    "            score+=reward\n",
    "            if done: break\n",
    "\n",
    "        # IF our score is higher than our threshold, we'd like to save\n",
    "        # every move we made\n",
    "        # NOTE the reinforcement methodology here. \n",
    "        # all we're doing is reinforcing the score, we're not trying \n",
    "        # to influence the machine in any way as to HOW that score is \n",
    "        # reached.\n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:\n",
    "                # convert to one-hot (this is the output layer for our neural network)\n",
    "                if data[1] == 1:\n",
    "                    output = [0,1]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1,0]\n",
    "                    \n",
    "                # saving our training data\n",
    "                training_data.append([data[0], output])\n",
    "\n",
    "        # reset env to play again\n",
    "        env.reset()\n",
    "        # save overall scores\n",
    "        scores.append(score)\n",
    "    \n",
    "    # just in case you wanted to reference later\n",
    "    training_data_save = np.array(training_data)\n",
    "    np.save('saved.npy',training_data_save)\n",
    "    \n",
    "    # some stats here, to further illustrate the neural network magic!\n",
    "    print('Average accepted score:',mean(accepted_scores))\n",
    "    print('Median score for accepted scores:',median(accepted_scores))\n",
    "    print(Counter(accepted_scores))\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(input_size):\n",
    "\n",
    "    network = input_data(shape=[None, input_size, 1], name='input')\n",
    "\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 256, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 512, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 256, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 2, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(training_data, model=False):\n",
    "\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)\n",
    "    y = [i[1] for i in training_data]\n",
    "\n",
    "    if not model:\n",
    "        model = neural_network_model(input_size = len(X[0]))\n",
    "    \n",
    "    model.fit({'input': X}, {'targets': y}, n_epoch=5, snapshot_step=500, show_metric=True, run_id='openai_learning')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toufik/anaconda3/envs/workshop/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score: 61.31266846361186\n",
      "Median score for accepted scores: 57.0\n",
      "Counter({50.0: 36, 51.0: 34, 52.0: 29, 53.0: 26, 54.0: 25, 57.0: 16, 55.0: 16, 61.0: 15, 58.0: 13, 62.0: 13, 56.0: 11, 64.0: 10, 63.0: 9, 60.0: 9, 72.0: 8, 65.0: 7, 59.0: 7, 67.0: 6, 70.0: 6, 68.0: 6, 66.0: 5, 78.0: 5, 73.0: 4, 84.0: 4, 76.0: 4, 82.0: 3, 80.0: 3, 87.0: 3, 75.0: 3, 77.0: 3, 71.0: 3, 88.0: 3, 69.0: 3, 79.0: 3, 81.0: 2, 103.0: 2, 93.0: 2, 74.0: 2, 85.0: 2, 105.0: 1, 99.0: 1, 147.0: 1, 90.0: 1, 86.0: 1, 98.0: 1, 97.0: 1, 131.0: 1, 89.0: 1, 83.0: 1})\n"
     ]
    }
   ],
   "source": [
    "training_data = initial_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1749  | total loss: \u001b[1m\u001b[32m0.66026\u001b[0m\u001b[0m | time: 2.483s\n",
      "| Adam | epoch: 005 | loss: 0.66026 - acc: 0.6213 -- iter: 22336/22376\n",
      "Training Step: 1750  | total loss: \u001b[1m\u001b[32m0.66599\u001b[0m\u001b[0m | time: 2.491s\n",
      "| Adam | epoch: 005 | loss: 0.66599 - acc: 0.6092 -- iter: 22376/22376\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = train_model(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 200.0\n",
      "choice 1:0.4995  choice 0:0.5005\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(10):\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        env.render()\n",
    "\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
    "\n",
    "        choices.append(action)\n",
    "                \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        game_memory.append([new_observation, action])\n",
    "        score+=reward\n",
    "        if done: break\n",
    "\n",
    "    scores.append(score)\n",
    "print('Average Score:',sum(scores)/len(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "print(score_requirement)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOUNTAIN CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import gym\n",
    "np.random.seed(0)\n",
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Agent:\n",
    "    def decide(self, observation, rand= False):\n",
    "        position, velocity = observation\n",
    "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
    "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lb < velocity < ub:\n",
    "            action = 2 # push right\n",
    "        else:\n",
    "            action = 0 # push left\n",
    "        if rand:\n",
    "            action = random.choice([0, 2])\n",
    "        return action\n",
    "\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_once(env, agent, render=False, verbose=False):\n",
    "    observation = env.reset()\n",
    "    episode_reward = 0.\n",
    "    for step in itertools.count():\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = agent.decide(observation, rand= True)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    if verbose:\n",
    "        print('get {} rewards in {} steps'.format(\n",
    "                episode_reward, step + 1))\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average episode rewards = -200.0\n"
     ]
    }
   ],
   "source": [
    "episode_rewards = [play_once(env, agent) for _ in range(100)]\n",
    "print('average episode rewards = {}'.format(np.mean(episode_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    episode_rewards = play_once(env, agent, render=True)\n",
    "#print('average episode rewards = {}'.format(np.mean(episode_rewards)))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sarsa lemda\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileCoder:\n",
    "    def __init__(self, layers, features):\n",
    "        \"\"\" \n",
    "        Parameters\n",
    "        - layers: int, the number of layers in tile coding\n",
    "        - features: int, the number of features, also the shape of weights\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.features = features\n",
    "        self.codebook = {}\n",
    "    \n",
    "    def get_feature(self, codeword):\n",
    "        if codeword in self.codebook:\n",
    "            return self.codebook[codeword]\n",
    "        count = len(self.codebook)\n",
    "        if count >= self.features: # collide when codebook is full\n",
    "            return hash(codeword) % self.features\n",
    "        else:\n",
    "            self.codebook[codeword] = count\n",
    "            return count\n",
    "        \n",
    "    def __call__(self, floats=(), ints=()):\n",
    "        \"\"\" \n",
    "        Parameters\n",
    "        - floats: tuple of floats, each of which is within [0., 1.]\n",
    "        - ints: tuple of ints\n",
    "        Returns\n",
    "        - features : list of ints\n",
    "        \"\"\"\n",
    "        dim = len(floats)\n",
    "        scaled_floats = tuple(f * self.layers * self.layers for f in floats)\n",
    "        features = []\n",
    "        for layer in range(self.layers):\n",
    "            codeword = (layer,) + tuple(int((f + (1 + dim * i) * layer) / self.layers) \\\n",
    "                    for i, f in enumerate(scaled_floats)) + ints\n",
    "            feature = self.get_feature(codeword)\n",
    "            features.append(feature)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent:\n",
    "    def __init__(self, env, layers=8, features=2000, gamma=1.,\n",
    "                learning_rate=0.03, epsilon=0.001):\n",
    "        self.action_n = env.action_space.n\n",
    "        self.obs_low = env.observation_space.low\n",
    "        self.obs_scale = env.observation_space.high - env.observation_space.low\n",
    "        self.encoder = TileCoder(layers, features)\n",
    "        self.w = np.zeros(features)\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def encode(self, observation, action):\n",
    "        states = tuple((observation - self.obs_low) / self.obs_scale)\n",
    "        actions = (action,)\n",
    "        return self.encoder(states, actions)\n",
    "    \n",
    "    def get_q(self, observation, action):\n",
    "        features = self.encode(observation, action)\n",
    "        return self.w[features].sum()\n",
    "    \n",
    "    def decide(self, observation):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.action_n)\n",
    "        else:\n",
    "            qs = [self.get_q(observation, action) for action in range(self.action_n)]\n",
    "            return np.argmax(qs)\n",
    "        \n",
    "    def learn(self, observation, action, reward, observation_next, done, action_next=None):\n",
    "        u = reward\n",
    "        if not done:\n",
    "            u += (self.gamma * self.get_q(observation_next, action_next))\n",
    "        delta = u - self.get_q(observation, action)\n",
    "        features = self.encode(observation, action)\n",
    "        self.w[features] += (self.learning_rate * delta)\n",
    "\n",
    "\n",
    "class SARSALambdaAgent(SARSAAgent):\n",
    "    def __init__(self, env, layers=8, features=2000, gamma=1.,\n",
    "                learning_rate=0.03, epsilon=0.001, lambd=0.9):\n",
    "        super().__init__(env=env, layers=layers, features=features,\n",
    "                gamma=gamma, learning_rate=learning_rate, epsilon=epsilon)\n",
    "        self.lambd = lambd\n",
    "        self.z = np.zeros(features)\n",
    "        \n",
    "    def learn(self, observation, action, reward, observation_next, done, action_next=None):\n",
    "        u = reward\n",
    "        if not done:\n",
    "            u += (self.gamma * self.get_q(observation_next, action_next))\n",
    "            self.z *= (self.gamma * self.lambd)\n",
    "            features = self.encode(observation, action)\n",
    "            self.z[features] = 1. # replacement trace\n",
    "        delta = u - self.get_q(observation, action)\n",
    "        self.w += (self.learning_rate * delta * self.z)\n",
    "        if done:\n",
    "            self.z = np.zeros_like(self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sarsa(env, agent, train=False, render=False):\n",
    "    episode_reward = 0\n",
    "    observation = env.reset()\n",
    "    action = agent.decide(observation)\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        observation_next, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            if train:\n",
    "                agent.learn(observation, action, reward, observation_next, done)\n",
    "            break\n",
    "        action_next = agent.decide(observation_next)\n",
    "        if train:\n",
    "            agent.learn(observation, action, reward, observation_next, done, action_next)\n",
    "        observation, action = observation_next, action_next\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(0)\n",
    "#env = gym.wrappers.Monitor(env, \"./records\", video_callable=lambda _:True)\n",
    "\n",
    "agent = SARSALambdaAgent(env)  \n",
    "\n",
    "episodes = 75\n",
    "episode_rewards = []\n",
    "for episode in range(episodes):\n",
    "    episode_reward = play_sarsa(env, agent, train=True)\n",
    "    episode_rewards.append(episode_reward)\n",
    "    \n",
    "plt.plot(episode_rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "episode_rewards = []\n",
    "for episode in range(episodes):\n",
    "    episode_reward = play_sarsa(env, agent, train=True, render=True)\n",
    "    episode_rewards.append(episode_reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
